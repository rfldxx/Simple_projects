#### Lazy FCA
Реализован стандарный Lazy FCA на С++:

* Каждый тестовой объект попарно пересекается с каждым объектом из тренировочных данных - и в итоге определяется является ли этот **тренировочный** объект классификатором (см. функция ```CountOfClassifier()``` и класс ```AlphaWeakClassifier{alpha}```)

* Для этого ищется кол-во вхождений этого пересечения в тренировочные объекты$^+$ и в тренировочные объекты$^-$ (см. функция ```count()```)

* По количеству # $^{+} $ и по количеству # $^{-} $ ```AlphaWeakClassifier{alpha}``` определяет является ли рассматриваемый **тренировочный** объект классификатором (# $^{-} < \alpha \cdot ($ # $^{-} + $ # $^{+} )$)

* Наконец, класс ```Predictor``` на основе количества положительных и отрицательных классификаторов для каждого тестового объекта предсказывает его класс

Признаки брались как в baseline. \
Единственное изменение использование $\alpha$-weak гипотез и нормировка количества классификаторов в итогов ```Predictor```. \
> $\alpha = \{0.01, 0.03, 0.05\}$ - дали одинаковый f1_score $ = 0.625$

#### Особености реализации
Необходимо подготовить признаки и сохранить их в формате csv с разделителем в виде пробелов, например на питоне:
```
# Сохранение в CSV
X_train.to_csv('X_train.csv', index=False, sep='\t')
```

Также в программе необходимо самому вбить кол-во признаков $M$.

Супер проверок программы не проводилось, но кол-во ```positive_classifiers``` и кол-во ```negative_classifiers``` для каждого тестового объекта и итоговый ```f1_score``` совпадают с реализацией на python (https://gitlab.com/Al_Toretto/lazy_fca_learning/-/blob/main/lazy_fca.ipynb).

> Компилировать: ```g++ naive.cpp -O3``` \
Версия на python работает ~45 минут в google colab, текущая реализация (на моем пк) - 15 секунд.

